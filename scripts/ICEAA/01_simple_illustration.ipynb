{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_simple_illustration\n",
    "\n",
    "Simple illustration of Penalized-Constrained Regression WITHOUT the library.\n",
    "Demonstrates the core concept: combining ElasticNet penalty with bound constraints.\n",
    "\n",
    "This script is intentionally concise (<100 lines) for paper illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n, T1, b_true, c_true = 20, 100, -0.152, -0.074  # 90% learning, 95% rate\n",
    "\n",
    "# Simulate correlated lot data\n",
    "lot_qty = np.round(5 * 1.3 ** np.arange(n) + np.random.uniform(-2, 2, n)).astype(int)\n",
    "lot_qty = np.clip(lot_qty, 1, None)\n",
    "midpoints = np.cumsum(lot_qty) - lot_qty/2  # Approximate midpoints\n",
    "\n",
    "# Generate costs with 10% CV error\n",
    "true_cost = T1 * (midpoints ** b_true) * (lot_qty ** c_true)\n",
    "observed_cost = true_cost * np.exp(np.random.normal(0, 0.1, n))\n",
    "\n",
    "# Log transform for linear regression\n",
    "X = np.column_stack([np.log(midpoints), np.log(lot_qty)])\n",
    "y = np.log(observed_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SIMPLE ILLUSTRATION: OLS vs Ridge vs Constrained vs Penalized-Constrained\")\n",
    "print(\"=\"*70)\n",
    "print(f\"True parameters: T1={T1}, b={b_true:.4f}, c={c_true:.4f}\")\n",
    "print(f\"Correlation between log(midpoint) and log(quantity): {np.corrcoef(X[:,0], X[:,1])[0,1]:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = LinearRegression().fit(X, y)\n",
    "print(f\"OLS:         b={ols.coef_[0]:+.4f}, c={ols.coef_[1]:+.4f}, T1={np.exp(ols.intercept_):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.1).fit(X, y)\n",
    "print(f\"Ridge:       b={ridge.coef_[0]:+.4f}, c={ridge.coef_[1]:+.4f}, T1={np.exp(ridge.intercept_):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Constrained Only (no penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_sse(params, X, y):\n",
    "    coef, intercept = params[:2], params[2]\n",
    "    return np.sum((y - X @ coef - intercept) ** 2)\n",
    "\n",
    "bounds_constrained = [(-1, 0), (-1, 0), (None, None)]  # b≤0, c≤0, intercept free\n",
    "x0 = np.append(ols.coef_, ols.intercept_)\n",
    "x0[:2] = np.clip(x0[:2], -1, 0)  # Clip to bounds\n",
    "\n",
    "res_constrained = minimize(objective_sse, x0, args=(X, y), method='SLSQP', bounds=bounds_constrained)\n",
    "print(f\"Constrained: b={res_constrained.x[0]:+.4f}, c={res_constrained.x[1]:+.4f}, \"\n",
    "      f\"T1={np.exp(res_constrained.x[2]):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Penalized-Constrained (ElasticNet + Bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_penalized(params, X, y, alpha=0.1, l1_ratio=0.5):\n",
    "    coef, intercept = params[:2], params[2]\n",
    "    sse = np.sum((y - X @ coef - intercept) ** 2)\n",
    "    l1 = alpha * l1_ratio * np.sum(np.abs(coef))\n",
    "    l2 = 0.5 * alpha * (1 - l1_ratio) * np.sum(coef ** 2)\n",
    "    return sse + l1 + l2\n",
    "\n",
    "res_penalized = minimize(objective_penalized, x0, args=(X, y, 0.1, 0.5), \n",
    "                         method='SLSQP', bounds=bounds_constrained)\n",
    "print(f\"Pen+Constr:  b={res_penalized.x[0]:+.4f}, c={res_penalized.x[1]:+.4f}, \"\n",
    "      f\"T1={np.exp(res_penalized.x[2]):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COEFFICIENT ERROR COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<15} {'b error':>10} {'c error':>10} {'R²':>8}\")\n",
    "print(\"-\"*45)\n",
    "\n",
    "methods = [\n",
    "    ('OLS', ols.coef_[0], ols.coef_[1], ols.score(X, y)),\n",
    "    ('Ridge', ridge.coef_[0], ridge.coef_[1], ridge.score(X, y)),\n",
    "    ('Constrained', res_constrained.x[0], res_constrained.x[1], \n",
    "     1 - np.sum((y - X @ res_constrained.x[:2] - res_constrained.x[2])**2) / np.sum((y - y.mean())**2)),\n",
    "    ('Pen+Constr', res_penalized.x[0], res_penalized.x[1],\n",
    "     1 - np.sum((y - X @ res_penalized.x[:2] - res_penalized.x[2])**2) / np.sum((y - y.mean())**2)),\n",
    "]\n",
    "\n",
    "for name, b_est, c_est, r2 in methods:\n",
    "    b_err = abs(b_est - b_true)\n",
    "    c_err = abs(c_est - c_true)\n",
    "    sign_ok = \"✓\" if (b_est <= 0 and c_est <= 0) else \"✗\"\n",
    "    print(f\"{name:<15} {b_err:>10.4f} {c_err:>10.4f} {r2:>8.4f}  {sign_ok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT: Penalized-Constrained combines regularization stability\")\n",
    "print(\"with domain knowledge (negative slopes), giving the best of both worlds.\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
