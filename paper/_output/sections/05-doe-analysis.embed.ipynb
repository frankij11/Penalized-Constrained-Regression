{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ],
   "id": "41246b39-81dc-4301-8b41-b89cc53e73b8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [],
   "id": "473a07e4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: setup-doe\n",
    "#| include: false\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for pyproject.toml\n",
    "def find_project_root():\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return current.parent.parent  # Fallback\n",
    "\n",
    "project_root = find_project_root()\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / \"scripts\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from scripts.ICEAA.analysis import load_simulation_results\n",
    "\n",
    "df = load_simulation_results()\n",
    "\n",
    "# Try importing pingouin for statistical tests\n",
    "try:\n",
    "    import pingouin as pg\n",
    "    HAS_PINGOUIN = True\n",
    "except ImportError:\n",
    "    HAS_PINGOUIN = False\n",
    "    print(\"Note: Install pingouin for full statistical analysis: pip install pingouin\")"
   ],
   "id": "setup-doe"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides rigorous statistical analysis using Design of Experiments (DOE) methodology.\n",
    "\n",
    "## Repeated Measures ANOVA\n",
    "\n",
    "We use repeated measures ANOVA to test whether model choice significantly affects performance, accounting for the fact that all models are evaluated on the same data scenarios."
   ],
   "id": "0367a952"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: rm-anova\n",
    "#| eval:\n",
    "#|   value: HAS_PINGOUIN\n",
    "#|   tag: '!expr'\n",
    "# Create scenario ID for repeated measures structure\n",
    "scenario_cols = ['n_lots', 'target_correlation', 'cv_error', 'learning_rate', 'rate_effect', 'replication']\n",
    "df['scenario_id'] = df.groupby(scenario_cols).ngroup()\n",
    "\n",
    "# Focus on key models for statistical comparison\n",
    "DOE_MODELS = ['OLS', 'PCReg_ConstrainOnly', 'PCReg_CV', 'PCReg_CV_Tight']\n",
    "df_doe = df[df['model_name'].isin(DOE_MODELS)].copy()\n",
    "\n",
    "# Repeated measures ANOVA\n",
    "rm_aov = pg.rm_anova(\n",
    "    data=df_doe,\n",
    "    dv='test_sspe',\n",
    "    within='model_name',\n",
    "    subject='scenario_id',\n",
    "    correction=True\n",
    ")\n",
    "\n",
    "print(\"Repeated Measures ANOVA Results:\")\n",
    "print(\"=\"*60)\n",
    "display(rm_aov)\n",
    "\n",
    "# Extract key statistics\n",
    "eta_sq_col = 'np2' if 'np2' in rm_aov.columns else 'ng2'\n",
    "eta_sq = rm_aov[eta_sq_col].values[0]\n",
    "f_val = rm_aov['F'].values[0]\n",
    "p_col = 'p-GG-corr' if 'p-GG-corr' in rm_aov.columns else 'p-unc'\n",
    "p_val = rm_aov[p_col].values[0]\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  F-statistic: {f_val:.2f}\")\n",
    "print(f\"  p-value: {p_val:.4e}\")\n",
    "print(f\"  Effect size (η²): {eta_sq:.4f}\")\n",
    "print(f\"  Model choice explains {eta_sq*100:.1f}% of variance in test SSPE\")"
   ],
   "id": "rm-anova"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Comparisons"
   ],
   "id": "042f993d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: pairwise\n",
    "#| eval:\n",
    "#|   value: HAS_PINGOUIN\n",
    "#|   tag: '!expr'\n",
    "pairwise = pg.pairwise_tests(\n",
    "    data=df_doe,\n",
    "    dv='test_sspe',\n",
    "    within='model_name',\n",
    "    subject='scenario_id',\n",
    "    padjust='holm',\n",
    "    effsize='hedges'\n",
    ")\n",
    "\n",
    "print(\"Pairwise Comparisons (Holm-Bonferroni corrected):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Focus on key comparisons\n",
    "key_pairs = [\n",
    "    ('PCReg_CV', 'OLS'),\n",
    "    ('PCReg_ConstrainOnly', 'OLS'),\n",
    "    ('PCReg_CV_Tight', 'OLS'),\n",
    "    ('PCReg_CV_Tight', 'PCReg_CV'),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for a, b in key_pairs:\n",
    "    row = pairwise[(pairwise['A'] == a) & (pairwise['B'] == b)]\n",
    "    if len(row) == 0:\n",
    "        row = pairwise[(pairwise['A'] == b) & (pairwise['B'] == a)]\n",
    "\n",
    "    if len(row) > 0:\n",
    "        row = row.iloc[0]\n",
    "        g = row['hedges']\n",
    "        p = row['p-corr']\n",
    "\n",
    "        sig = '***' if p < 0.001 else ('**' if p < 0.01 else ('*' if p < 0.05 else 'ns'))\n",
    "        g_abs = abs(g)\n",
    "        g_size = 'negligible' if g_abs < 0.2 else ('small' if g_abs < 0.5 else ('medium' if g_abs < 0.8 else 'large'))\n",
    "        better = a if g < 0 else b\n",
    "\n",
    "        results.append({\n",
    "            'Comparison': f'{a} vs {b}',\n",
    "            'Hedges g': f'{g:.4f}',\n",
    "            'p-value': f'{p:.4f}',\n",
    "            'Significance': sig,\n",
    "            'Effect Size': g_size,\n",
    "            'Better Model': better\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ],
   "id": "pairwise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win Rate Analysis"
   ],
   "id": "a32d843a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PCReg_ConstrainOnly vs OLS Win Rate Analysis\n",
      "============================================================\n",
      "  Overall Win Rate: 58.2% (3536/6075)\n",
      "  Binomial Test p-value: 7.4510e-38\n",
      "  ✓ PCReg significantly outperforms OLS (p < 0.05)"
     ]
    }
   ],
   "source": [
    "#| label: win-rates\n",
    "# Prepare wide format for win rate calculation\n",
    "scenario_cols = ['n_lots', 'target_correlation', 'cv_error', 'learning_rate', 'rate_effect', 'replication']\n",
    "df_wide = df.pivot_table(\n",
    "    index=scenario_cols,\n",
    "    columns='model_name',\n",
    "    values='test_sspe'\n",
    ").reset_index()\n",
    "\n",
    "# Overall win rate: PCReg_ConstrainOnly vs OLS\n",
    "if 'PCReg_ConstrainOnly' in df_wide.columns and 'OLS' in df_wide.columns:\n",
    "    df_wide['pcreg_wins'] = df_wide['PCReg_ConstrainOnly'] < df_wide['OLS']\n",
    "\n",
    "    overall_wins = df_wide['pcreg_wins'].sum()\n",
    "    overall_total = len(df_wide)\n",
    "    overall_rate = overall_wins / overall_total\n",
    "\n",
    "    # Binomial test\n",
    "    binom_result = stats.binomtest(overall_wins, overall_total, p=0.5, alternative='greater')\n",
    "\n",
    "    print(\"PCReg_ConstrainOnly vs OLS Win Rate Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Overall Win Rate: {overall_rate:.1%} ({overall_wins}/{overall_total})\")\n",
    "    print(f\"  Binomial Test p-value: {binom_result.pvalue:.4e}\")\n",
    "\n",
    "    if binom_result.pvalue < 0.05:\n",
    "        print(\"  ✓ PCReg significantly outperforms OLS (p < 0.05)\")"
   ],
   "id": "win-rates"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win Rates by Design Factor"
   ],
   "id": "95b27065"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Win Rates by Design Factor\n",
      "============================================================\n",
      "\n",
      "n_lots:\n",
      "  5: 65.5% (1327/2025) *\n",
      "  10: 59.3% (1200/2025) *\n",
      "  30: 49.8% (1009/2025) \n",
      "\n",
      "cv_error:\n",
      "  0.01: 71.8% (1453/2025) *\n",
      "  0.1: 56.5% (1145/2025) *\n",
      "  0.2: 46.3% (938/2025) \n",
      "\n",
      "target_correlation:\n",
      "  0.0: 62.3% (1261/2025) *\n",
      "  0.5: 55.4% (1122/2025) *\n",
      "  0.9: 56.9% (1153/2025) *\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ],
      "text/markdown": [
       "      Factor               Level   Win Rate   p-value   Significant\n",
       "  --- -------------------- ------- ---------- --------- -------------\n",
       "  0   n_lots               5.00    65.5%      0.0000    Yes\n",
       "  1   n_lots               10.00   59.3%      0.0000    Yes\n",
       "  2   n_lots               30.00   49.8%      0.5705    No\n",
       "  3   cv_error             0.01    71.8%      0.0000    Yes\n",
       "  4   cv_error             0.10    56.5%      0.0000    Yes\n",
       "  5   cv_error             0.20    46.3%      0.9996    No\n",
       "  6   target_correlation   0.00    62.3%      0.0000    Yes\n",
       "  7   target_correlation   0.50    55.4%      0.0000    Yes\n",
       "  8   target_correlation   0.90    56.9%      0.0000    Yes\n"
      ]
     }
    }
   ],
   "source": [
    "#| label: win-rates-by-factor\n",
    "FACTORS = ['n_lots', 'cv_error', 'target_correlation']\n",
    "\n",
    "print(\"Win Rates by Design Factor\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "win_rates = []\n",
    "for factor in FACTORS:\n",
    "    print(f\"\\n{factor}:\")\n",
    "    for level in sorted(df_wide[factor].unique()):\n",
    "        mask = df_wide[factor] == level\n",
    "        level_wins = df_wide.loc[mask, 'pcreg_wins'].sum()\n",
    "        level_total = mask.sum()\n",
    "        level_rate = level_wins / level_total\n",
    "\n",
    "        binom = stats.binomtest(level_wins, level_total, p=0.5, alternative='greater')\n",
    "        sig = '*' if binom.pvalue < 0.05 else ''\n",
    "\n",
    "        print(f\"  {level}: {level_rate:.1%} ({level_wins}/{level_total}) {sig}\")\n",
    "\n",
    "        win_rates.append({\n",
    "            'Factor': factor,\n",
    "            'Level': level,\n",
    "            'Win Rate': f'{level_rate:.1%}',\n",
    "            'p-value': f'{binom.pvalue:.4f}',\n",
    "            'Significant': 'Yes' if binom.pvalue < 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "# Display as table\n",
    "print(\"\\n\")\n",
    "win_rates_df = pd.DataFrame(win_rates)\n",
    "display(win_rates_df)"
   ],
   "id": "cell-win-rates-by-factor"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Statistical Findings\n",
    "\n",
    "Based on the statistical analysis:\n",
    "\n",
    "1.  **Model choice matters**: The repeated measures ANOVA confirms significant differences between models (p \\< 0.001)\n",
    "\n",
    "2.  **PCReg outperforms OLS**: The overall win rate exceeds 50% and is statistically significant\n",
    "\n",
    "3.  **Effect sizes are meaningful**: Hedges’ g values indicate practically important differences\n",
    "\n",
    "4.  **Context matters**: Win rates vary substantially by design factor levels, suggesting PCReg is particularly valuable in specific conditions"
   ],
   "id": "c56ecdf3"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- -->"
   ],
   "id": "074241ff-463c-49e5-8984-5fb64358ce94"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```` markdown\n",
    "# Statistical Analysis {#sec-doe-analysis}\n",
    "\n",
    "quarto-executable-code-5450563D\n",
    "\n",
    "```python\n",
    "#| label: setup-doe\n",
    "#| include: false\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for pyproject.toml\n",
    "def find_project_root():\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return current.parent.parent  # Fallback\n",
    "\n",
    "project_root = find_project_root()\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / \"scripts\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from scripts.ICEAA.analysis import load_simulation_results\n",
    "\n",
    "df = load_simulation_results()\n",
    "\n",
    "# Try importing pingouin for statistical tests\n",
    "try:\n",
    "    import pingouin as pg\n",
    "    HAS_PINGOUIN = True\n",
    "except ImportError:\n",
    "    HAS_PINGOUIN = False\n",
    "    print(\"Note: Install pingouin for full statistical analysis: pip install pingouin\")\n",
    "```\n",
    "\n",
    "This section provides rigorous statistical analysis using Design of Experiments (DOE) methodology.\n",
    "\n",
    "## Repeated Measures ANOVA\n",
    "\n",
    "We use repeated measures ANOVA to test whether model choice significantly affects performance, accounting for the fact that all models are evaluated on the same data scenarios.\n",
    "\n",
    "quarto-executable-code-5450563D\n",
    "\n",
    "```python\n",
    "#| label: rm-anova\n",
    "#| eval: !expr HAS_PINGOUIN\n",
    "\n",
    "# Create scenario ID for repeated measures structure\n",
    "scenario_cols = ['n_lots', 'target_correlation', 'cv_error', 'learning_rate', 'rate_effect', 'replication']\n",
    "df['scenario_id'] = df.groupby(scenario_cols).ngroup()\n",
    "\n",
    "# Focus on key models for statistical comparison\n",
    "DOE_MODELS = ['OLS', 'PCReg_ConstrainOnly', 'PCReg_CV', 'PCReg_CV_Tight']\n",
    "df_doe = df[df['model_name'].isin(DOE_MODELS)].copy()\n",
    "\n",
    "# Repeated measures ANOVA\n",
    "rm_aov = pg.rm_anova(\n",
    "    data=df_doe,\n",
    "    dv='test_sspe',\n",
    "    within='model_name',\n",
    "    subject='scenario_id',\n",
    "    correction=True\n",
    ")\n",
    "\n",
    "print(\"Repeated Measures ANOVA Results:\")\n",
    "print(\"=\"*60)\n",
    "display(rm_aov)\n",
    "\n",
    "# Extract key statistics\n",
    "eta_sq_col = 'np2' if 'np2' in rm_aov.columns else 'ng2'\n",
    "eta_sq = rm_aov[eta_sq_col].values[0]\n",
    "f_val = rm_aov['F'].values[0]\n",
    "p_col = 'p-GG-corr' if 'p-GG-corr' in rm_aov.columns else 'p-unc'\n",
    "p_val = rm_aov[p_col].values[0]\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  F-statistic: {f_val:.2f}\")\n",
    "print(f\"  p-value: {p_val:.4e}\")\n",
    "print(f\"  Effect size (η²): {eta_sq:.4f}\")\n",
    "print(f\"  Model choice explains {eta_sq*100:.1f}% of variance in test SSPE\")\n",
    "```\n",
    "\n",
    "## Pairwise Comparisons\n",
    "\n",
    "quarto-executable-code-5450563D\n",
    "\n",
    "```python\n",
    "#| label: pairwise\n",
    "#| eval: !expr HAS_PINGOUIN\n",
    "\n",
    "pairwise = pg.pairwise_tests(\n",
    "    data=df_doe,\n",
    "    dv='test_sspe',\n",
    "    within='model_name',\n",
    "    subject='scenario_id',\n",
    "    padjust='holm',\n",
    "    effsize='hedges'\n",
    ")\n",
    "\n",
    "print(\"Pairwise Comparisons (Holm-Bonferroni corrected):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Focus on key comparisons\n",
    "key_pairs = [\n",
    "    ('PCReg_CV', 'OLS'),\n",
    "    ('PCReg_ConstrainOnly', 'OLS'),\n",
    "    ('PCReg_CV_Tight', 'OLS'),\n",
    "    ('PCReg_CV_Tight', 'PCReg_CV'),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for a, b in key_pairs:\n",
    "    row = pairwise[(pairwise['A'] == a) & (pairwise['B'] == b)]\n",
    "    if len(row) == 0:\n",
    "        row = pairwise[(pairwise['A'] == b) & (pairwise['B'] == a)]\n",
    "\n",
    "    if len(row) > 0:\n",
    "        row = row.iloc[0]\n",
    "        g = row['hedges']\n",
    "        p = row['p-corr']\n",
    "\n",
    "        sig = '***' if p < 0.001 else ('**' if p < 0.01 else ('*' if p < 0.05 else 'ns'))\n",
    "        g_abs = abs(g)\n",
    "        g_size = 'negligible' if g_abs < 0.2 else ('small' if g_abs < 0.5 else ('medium' if g_abs < 0.8 else 'large'))\n",
    "        better = a if g < 0 else b\n",
    "\n",
    "        results.append({\n",
    "            'Comparison': f'{a} vs {b}',\n",
    "            'Hedges g': f'{g:.4f}',\n",
    "            'p-value': f'{p:.4f}',\n",
    "            'Significance': sig,\n",
    "            'Effect Size': g_size,\n",
    "            'Better Model': better\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "```\n",
    "\n",
    "## Win Rate Analysis\n",
    "\n",
    "quarto-executable-code-5450563D\n",
    "\n",
    "```python\n",
    "#| label: win-rates\n",
    "\n",
    "# Prepare wide format for win rate calculation\n",
    "scenario_cols = ['n_lots', 'target_correlation', 'cv_error', 'learning_rate', 'rate_effect', 'replication']\n",
    "df_wide = df.pivot_table(\n",
    "    index=scenario_cols,\n",
    "    columns='model_name',\n",
    "    values='test_sspe'\n",
    ").reset_index()\n",
    "\n",
    "# Overall win rate: PCReg_ConstrainOnly vs OLS\n",
    "if 'PCReg_ConstrainOnly' in df_wide.columns and 'OLS' in df_wide.columns:\n",
    "    df_wide['pcreg_wins'] = df_wide['PCReg_ConstrainOnly'] < df_wide['OLS']\n",
    "\n",
    "    overall_wins = df_wide['pcreg_wins'].sum()\n",
    "    overall_total = len(df_wide)\n",
    "    overall_rate = overall_wins / overall_total\n",
    "\n",
    "    # Binomial test\n",
    "    binom_result = stats.binomtest(overall_wins, overall_total, p=0.5, alternative='greater')\n",
    "\n",
    "    print(\"PCReg_ConstrainOnly vs OLS Win Rate Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Overall Win Rate: {overall_rate:.1%} ({overall_wins}/{overall_total})\")\n",
    "    print(f\"  Binomial Test p-value: {binom_result.pvalue:.4e}\")\n",
    "\n",
    "    if binom_result.pvalue < 0.05:\n",
    "        print(\"  ✓ PCReg significantly outperforms OLS (p < 0.05)\")\n",
    "```\n",
    "\n",
    "## Win Rates by Design Factor\n",
    "\n",
    "quarto-executable-code-5450563D\n",
    "\n",
    "```python\n",
    "#| label: win-rates-by-factor\n",
    "\n",
    "FACTORS = ['n_lots', 'cv_error', 'target_correlation']\n",
    "\n",
    "print(\"Win Rates by Design Factor\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "win_rates = []\n",
    "for factor in FACTORS:\n",
    "    print(f\"\\n{factor}:\")\n",
    "    for level in sorted(df_wide[factor].unique()):\n",
    "        mask = df_wide[factor] == level\n",
    "        level_wins = df_wide.loc[mask, 'pcreg_wins'].sum()\n",
    "        level_total = mask.sum()\n",
    "        level_rate = level_wins / level_total\n",
    "\n",
    "        binom = stats.binomtest(level_wins, level_total, p=0.5, alternative='greater')\n",
    "        sig = '*' if binom.pvalue < 0.05 else ''\n",
    "\n",
    "        print(f\"  {level}: {level_rate:.1%} ({level_wins}/{level_total}) {sig}\")\n",
    "\n",
    "        win_rates.append({\n",
    "            'Factor': factor,\n",
    "            'Level': level,\n",
    "            'Win Rate': f'{level_rate:.1%}',\n",
    "            'p-value': f'{binom.pvalue:.4f}',\n",
    "            'Significant': 'Yes' if binom.pvalue < 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "# Display as table\n",
    "print(\"\\n\")\n",
    "win_rates_df = pd.DataFrame(win_rates)\n",
    "display(win_rates_df)\n",
    "```\n",
    "\n",
    "## Key Statistical Findings\n",
    "\n",
    "Based on the statistical analysis:\n",
    "\n",
    "1. **Model choice matters**: The repeated measures ANOVA confirms significant differences between models (p < 0.001)\n",
    "\n",
    "2. **PCReg outperforms OLS**: The overall win rate exceeds 50% and is statistically significant\n",
    "\n",
    "3. **Effect sizes are meaningful**: Hedges' g values indicate practically important differences\n",
    "\n",
    "4. **Context matters**: Win rates vary substantially by design factor levels, suggesting PCReg is particularly valuable in specific conditions\n",
    "````"
   ],
   "id": "628880cc-97d3-4181-b042-8e67efda1552"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
