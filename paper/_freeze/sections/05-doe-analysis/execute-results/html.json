{
  "hash": "022d90c2aefc7a52cf3ac1e31d06ce12",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Statistical Analysis\n---\n\n\n:::{#473a07e4 .cell .markdown}\n\n:::\n\n::: {#setup-doe .cell .hidden execution_count=1}\n``` {}\n#| label: setup-doe\n#| include: false\nimport sys\nfrom pathlib import Path\n\n# Find project root by looking for pyproject.toml\ndef find_project_root():\n    current = Path.cwd()\n    for parent in [current] + list(current.parents):\n        if (parent / \"pyproject.toml\").exists():\n            return parent\n    return current.parent.parent  # Fallback\n\nproject_root = find_project_root()\nsys.path.insert(0, str(project_root))\nsys.path.insert(0, str(project_root / \"scripts\"))\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom scripts.ICEAA.analysis import load_simulation_results\n\ndf = load_simulation_results()\n\n# Try importing pingouin for statistical tests\ntry:\n    import pingouin as pg\n    HAS_PINGOUIN = True\nexcept ImportError:\n    HAS_PINGOUIN = False\n    print(\"Note: Install pingouin for full statistical analysis: pip install pingouin\")\n```\n:::\n\n\n:::{#0367a952 .cell .markdown}\nThis section provides rigorous statistical analysis using Design of Experiments (DOE) methodology.\n\n## Repeated Measures ANOVA\n\nWe use repeated measures ANOVA to test whether model choice significantly affects performance, accounting for the fact that all models are evaluated on the same data scenarios.\n:::\n\n::: {#rm-anova .cell execution_count=2}\n``` {}\n#| label: rm-anova\n#| eval:\n#|   value: HAS_PINGOUIN\n#|   tag: '!expr'\n# Create scenario ID for repeated measures structure\nscenario_cols = ['n_lots', 'target_correlation', 'cv_error', 'learning_rate', 'rate_effect', 'replication']\ndf['scenario_id'] = df.groupby(scenario_cols).ngroup()\n\n# Focus on key models for statistical comparison\nDOE_MODELS = ['OLS', 'PCReg_ConstrainOnly', 'PCReg_CV', 'PCReg_CV_Tight']\ndf_doe = df[df['model_name'].isin(DOE_MODELS)].copy()\n\n# Repeated measures ANOVA\nrm_aov = pg.rm_anova(\n    data=df_doe,\n    dv='test_sspe',\n    within='model_name',\n    subject='scenario_id',\n    correction=True\n)\n\nprint(\"Repeated Measures ANOVA Results:\")\nprint(\"=\"*60)\ndisplay(rm_aov)\n\n# Extract key statistics\neta_sq_col = 'np2' if 'np2' in rm_aov.columns else 'ng2'\neta_sq = rm_aov[eta_sq_col].values[0]\nf_val = rm_aov['F'].values[0]\np_col = 'p-GG-corr' if 'p-GG-corr' in rm_aov.columns else 'p-unc'\np_val = rm_aov[p_col].values[0]\n\nprint(f\"\\nInterpretation:\")\nprint(f\"  F-statistic: {f_val:.2f}\")\nprint(f\"  p-value: {p_val:.4e}\")\nprint(f\"  Effect size (η²): {eta_sq:.4f}\")\nprint(f\"  Model choice explains {eta_sq*100:.1f}% of variance in test SSPE\")\n```\n:::\n\n\n:::{#042f993d .cell .markdown}\n## Pairwise Comparisons\n:::\n\n::: {#pairwise .cell execution_count=3}\n``` {}\n#| label: pairwise\n#| eval:\n#|   value: HAS_PINGOUIN\n#|   tag: '!expr'\npairwise = pg.pairwise_tests(\n    data=df_doe,\n    dv='test_sspe',\n    within='model_name',\n    subject='scenario_id',\n    padjust='holm',\n    effsize='hedges'\n)\n\nprint(\"Pairwise Comparisons (Holm-Bonferroni corrected):\")\nprint(\"=\"*60)\n\n# Focus on key comparisons\nkey_pairs = [\n    ('PCReg_CV', 'OLS'),\n    ('PCReg_ConstrainOnly', 'OLS'),\n    ('PCReg_CV_Tight', 'OLS'),\n    ('PCReg_CV_Tight', 'PCReg_CV'),\n]\n\nresults = []\nfor a, b in key_pairs:\n    row = pairwise[(pairwise['A'] == a) & (pairwise['B'] == b)]\n    if len(row) == 0:\n        row = pairwise[(pairwise['A'] == b) & (pairwise['B'] == a)]\n\n    if len(row) > 0:\n        row = row.iloc[0]\n        g = row['hedges']\n        p = row['p-corr']\n\n        sig = '***' if p < 0.001 else ('**' if p < 0.01 else ('*' if p < 0.05 else 'ns'))\n        g_abs = abs(g)\n        g_size = 'negligible' if g_abs < 0.2 else ('small' if g_abs < 0.5 else ('medium' if g_abs < 0.8 else 'large'))\n        better = a if g < 0 else b\n\n        results.append({\n            'Comparison': f'{a} vs {b}',\n            'Hedges g': f'{g:.4f}',\n            'p-value': f'{p:.4f}',\n            'Significance': sig,\n            'Effect Size': g_size,\n            'Better Model': better\n        })\n\nresults_df = pd.DataFrame(results)\ndisplay(results_df)\n```\n:::\n\n\n:::{#a32d843a .cell .markdown}\n## Win Rate Analysis\n:::\n\n::: {#win-rates .cell execution_count=4}\n``` {}\n#| label: win-rates\n# Prepare wide format for win rate calculation\nscenario_cols = ['n_lots', 'target_correlation', 'cv_error', 'learning_rate', 'rate_effect', 'replication']\ndf_wide = df.pivot_table(\n    index=scenario_cols,\n    columns='model_name',\n    values='test_sspe'\n).reset_index()\n\n# Overall win rate: PCReg_ConstrainOnly vs OLS\nif 'PCReg_ConstrainOnly' in df_wide.columns and 'OLS' in df_wide.columns:\n    df_wide['pcreg_wins'] = df_wide['PCReg_ConstrainOnly'] < df_wide['OLS']\n\n    overall_wins = df_wide['pcreg_wins'].sum()\n    overall_total = len(df_wide)\n    overall_rate = overall_wins / overall_total\n\n    # Binomial test\n    binom_result = stats.binomtest(overall_wins, overall_total, p=0.5, alternative='greater')\n\n    print(\"PCReg_ConstrainOnly vs OLS Win Rate Analysis\")\n    print(\"=\"*60)\n    print(f\"  Overall Win Rate: {overall_rate:.1%} ({overall_wins}/{overall_total})\")\n    print(f\"  Binomial Test p-value: {binom_result.pvalue:.4e}\")\n\n    if binom_result.pvalue < 0.05:\n        print(\"  ✓ PCReg significantly outperforms OLS (p < 0.05)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPCReg_ConstrainOnly vs OLS Win Rate Analysis\n============================================================\n  Overall Win Rate: 58.2% (3536/6075)\n  Binomial Test p-value: 7.4510e-38\n  ✓ PCReg significantly outperforms OLS (p < 0.05)\n```\n:::\n:::\n\n\n:::{#95b27065 .cell .markdown}\n## Win Rates by Design Factor\n:::\n\n::: {#cell-win-rates-by-factor .cell execution_count=5}\n``` {}\n#| label: win-rates-by-factor\nFACTORS = ['n_lots', 'cv_error', 'target_correlation']\n\nprint(\"Win Rates by Design Factor\")\nprint(\"=\"*60)\n\nwin_rates = []\nfor factor in FACTORS:\n    print(f\"\\n{factor}:\")\n    for level in sorted(df_wide[factor].unique()):\n        mask = df_wide[factor] == level\n        level_wins = df_wide.loc[mask, 'pcreg_wins'].sum()\n        level_total = mask.sum()\n        level_rate = level_wins / level_total\n\n        binom = stats.binomtest(level_wins, level_total, p=0.5, alternative='greater')\n        sig = '*' if binom.pvalue < 0.05 else ''\n\n        print(f\"  {level}: {level_rate:.1%} ({level_wins}/{level_total}) {sig}\")\n\n        win_rates.append({\n            'Factor': factor,\n            'Level': level,\n            'Win Rate': f'{level_rate:.1%}',\n            'p-value': f'{binom.pvalue:.4f}',\n            'Significant': 'Yes' if binom.pvalue < 0.05 else 'No'\n        })\n\n# Display as table\nprint(\"\\n\")\nwin_rates_df = pd.DataFrame(win_rates)\ndisplay(win_rates_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWin Rates by Design Factor\n============================================================\n\nn_lots:\n  5: 65.5% (1327/2025) *\n  10: 59.3% (1200/2025) *\n  30: 49.8% (1009/2025) \n\ncv_error:\n  0.01: 71.8% (1453/2025) *\n  0.1: 56.5% (1145/2025) *\n  0.2: 46.3% (938/2025) \n\ntarget_correlation:\n  0.0: 62.3% (1261/2025) *\n  0.5: 55.4% (1122/2025) *\n  0.9: 56.9% (1153/2025) *\n\n\n```\n:::\n\n::: {#win-rates-by-factor .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Factor</th>\n      <th>Level</th>\n      <th>Win Rate</th>\n      <th>p-value</th>\n      <th>Significant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n_lots</td>\n      <td>5.00</td>\n      <td>65.5%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n_lots</td>\n      <td>10.00</td>\n      <td>59.3%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n_lots</td>\n      <td>30.00</td>\n      <td>49.8%</td>\n      <td>0.5705</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cv_error</td>\n      <td>0.01</td>\n      <td>71.8%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cv_error</td>\n      <td>0.10</td>\n      <td>56.5%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cv_error</td>\n      <td>0.20</td>\n      <td>46.3%</td>\n      <td>0.9996</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>target_correlation</td>\n      <td>0.00</td>\n      <td>62.3%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>target_correlation</td>\n      <td>0.50</td>\n      <td>55.4%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>target_correlation</td>\n      <td>0.90</td>\n      <td>56.9%</td>\n      <td>0.0000</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::{#c56ecdf3 .cell .markdown}\n## Key Statistical Findings\n\nBased on the statistical analysis:\n\n1. **Model choice matters**: The repeated measures ANOVA confirms significant differences between models (p < 0.001)\n\n2. **PCReg outperforms OLS**: The overall win rate exceeds 50% and is statistically significant\n\n3. **Effect sizes are meaningful**: Hedges' g values indicate practically important differences\n\n4. **Context matters**: Win rates vary substantially by design factor levels, suggesting PCReg is particularly valuable in specific conditions\n:::\n\n",
    "supporting": [
      "05-doe-analysis_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}